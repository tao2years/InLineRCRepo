#!/usr/bin/env python3
"""
æ”¹è¿›çš„RCç”Ÿæˆå™¨ - ä½¿ç”¨æ­£ç¡®çš„é€»è¾‘é€’è¿›å…³ç³»
"""

import json
import re
import os
from datetime import datetime
import requests
from typing import Dict, List, Any, Optional

class ImprovedRCGenerator:
    def __init__(self):
        self.api_key = "sk-q9fMcdnptLRU2oCLUN8JHORs4VS8rWJVqrwboB5SF8vrAyo8"
        
        self.api_url = "https://api2.aigcbest.top/v1/chat/completions"
        self.model = "gpt-4o-2024-08-06"
        
        # åŠ è½½æ”¹è¿›çš„prompt
        with open('RC_prompt_improved.txt', 'r', encoding='utf-8') as f:
            prompt_content = f.read()
        
        # è§£æprompt
        parts = prompt_content.split('(2) User Prompt - åŒæ–‡ä»¶è½®')
        self.system_prompt = parts[0].replace('(1) System Prompt\n', '').strip()
        self.user_template = parts[1].split('(3) User Prompt - é‚»å±…è½®')[0].strip()
        
    def load_benchmark(self, file_path: str) -> List[Dict]:
        """åŠ è½½benchmarkæ•°æ®"""
        benchmarks = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    benchmarks.append(json.loads(line))
        return benchmarks
    
    def extract_code_context(self, prompt: str) -> Dict[str, str]:
        """ä»promptä¸­æå–ä»£ç ä¸Šä¸‹æ–‡"""
        context_above_match = re.search(r'The context above is:\s*```java\s*(.*?)\s*```', prompt, re.DOTALL)
        context_below_match = re.search(r'The context below is:\s*```java\s*(.*?)\s*```', prompt, re.DOTALL)
        task_match = re.search(r'The new feature is (.+?)\.', prompt)
        
        return {
            'context_above': context_above_match.group(1).strip() if context_above_match else '',
            'context_below': context_below_match.group(1).strip() if context_below_match else '',
            'task': task_match.group(1).strip() if task_match else ''
        }
    
    def create_user_prompt(self, benchmark: Dict) -> str:
        """åˆ›å»ºç”¨æˆ·prompt"""
        context = self.extract_code_context(benchmark['prompt'])
        
        # æ„å»ºå®Œæ•´çš„æ–‡ä»¶å†…å®¹
        full_content = f"{context['context_above']}\n\n// [CURRENT TASK LOCATION]\n\n{context['context_below']}"
        
        # æ›¿æ¢æ¨¡æ¿å˜é‡
        user_prompt = self.user_template.format(
            instruction=context['task'],
            repo_path="/mock/repo",
            resolved_file_path=benchmark['extra_content']['file_path'],
            start=benchmark['extra_content']['start_line'],
            end=benchmark['extra_content']['end_line'],
            full_file_content=full_content
        )
        
        return user_prompt
    
    def call_llm(self, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨LLM API"""
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': self.model,
            'messages': [
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_prompt}
            ],
            'temperature': 0.7,
            'max_tokens': 2000
        }
        
        try:
            response = requests.post(self.api_url, headers=headers, json=data, timeout=60)
            response.raise_for_status()
            result = response.json()
            return result['choices'][0]['message']['content']
        except Exception as e:
            print(f"APIè°ƒç”¨å¤±è´¥: {e}")
            raise
    
    def parse_llm_response(self, response: str) -> Dict[str, Any]:
        """è§£æLLMå“åº”"""
        result = {'hunks': []}
        
        # æå–hunks_1, hunks_2, hunks_3
        for i in range(1, 4):
            pattern = f'### hunks_{i}.*?\n(.*?)(?=### hunks_|### notes|$)'
            match = re.search(pattern, response, re.DOTALL)
            if match:
                json_content = match.group(1).strip()
                # æ¸…ç†JSONå†…å®¹
                json_content = re.sub(r'```json\s*', '', json_content)
                json_content = re.sub(r'\s*```', '', json_content)
                
                try:
                    hunks = json.loads(json_content)
                    if isinstance(hunks, list):
                        result['hunks'].extend(hunks)
                    else:
                        result['hunks'].append(hunks)
                except json.JSONDecodeError as e:
                    print(f"è§£æhunks_{i}å¤±è´¥: {e}")
                    print(f"å†…å®¹: {json_content}")
        
        # æå–notes
        notes_match = re.search(r'### notes\s*(.*?)$', response, re.DOTALL)
        if notes_match:
            result['notes'] = notes_match.group(1).strip()
        else:
            result['notes'] = "é€’è¿›å¼å‡†å¤‡å·¥ä½œï¼Œä¸ºå®ç°å½“å‰ä»»åŠ¡é“ºå¹³é“è·¯ã€‚"
        
        return result
    
    def generate_rc_for_benchmark(self, benchmark: Dict, index: int) -> Optional[Dict]:
        """ä¸ºå•ä¸ªbenchmarkç”ŸæˆRC"""
        print(f"\nå¤„ç†ç¬¬{index}æ¡benchmark: {benchmark['id']}")
        
        try:
            # åˆ›å»ºç”¨æˆ·prompt
            user_prompt = self.create_user_prompt(benchmark)
            
            # è°ƒç”¨LLM
            print("è°ƒç”¨LLM...")
            response = self.call_llm(self.system_prompt, user_prompt)
            
            # ä¿å­˜å“åº”ç¼“å­˜
            cache_file = f"cache/improved_llm_cache_{index}_{benchmark['id'].replace('#', '_')}.json"
            os.makedirs('cache', exist_ok=True)
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump({'response': response, 'timestamp': datetime.now().isoformat()}, f, ensure_ascii=False, indent=2)
            
            print(f"LLMå“åº”å·²ç¼“å­˜åˆ°: {cache_file}")
            print(f"å“åº”å†…å®¹:\n{response}\n")
            
            # è§£æå“åº”
            parsed = self.parse_llm_response(response)
            
            if not parsed['hunks']:
                print("âŒ æœªèƒ½è§£æå‡ºæœ‰æ•ˆçš„hunks")
                return None
            
            print(f"âœ… æˆåŠŸè§£æå‡º{len(parsed['hunks'])}ä¸ªhunks")
            return {
                'hunks': parsed['hunks'],
                'notes': parsed['notes']
            }
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            return None
    
    def process_all_benchmarks(self, input_file: str, output_file: str):
        """å¤„ç†æ‰€æœ‰benchmark"""
        print("ğŸš€ å¼€å§‹å¤„ç†æ‰€æœ‰benchmark...")
        
        # åŠ è½½æ•°æ®
        benchmarks = self.load_benchmark(input_file)
        print(f"åŠ è½½äº†{len(benchmarks)}æ¡benchmark")
        
        results = []
        success_count = 0
        
        for i, benchmark in enumerate(benchmarks, 1):
            rc_context = self.generate_rc_for_benchmark(benchmark, i)
            
            if rc_context:
                benchmark['rc_context'] = rc_context
                success_count += 1
                print(f"âœ… ç¬¬{i}æ¡å¤„ç†æˆåŠŸ")
            else:
                print(f"âŒ ç¬¬{i}æ¡å¤„ç†å¤±è´¥")
            
            results.append(benchmark)
        
        # ä¿å­˜ç»“æœ
        with open(output_file, 'w', encoding='utf-8') as f:
            for result in results:
                f.write(json.dumps(result, ensure_ascii=False) + '\n')
        
        # ç”Ÿæˆç»Ÿè®¡
        stats = {
            'generation_time': datetime.now().isoformat(),
            'total_benchmarks': len(benchmarks),
            'successful_generations': success_count,
            'failed_generations': len(benchmarks) - success_count,
            'success_rate': f"{success_count/len(benchmarks)*100:.1f}%",
            'model': self.model
        }
        
        with open('logs/improved_gen_log.json', 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ‰ å¤„ç†å®Œæˆ!")
        print(f"æˆåŠŸç‡: {stats['success_rate']} ({success_count}/{len(benchmarks)})")
        print(f"ç»“æœä¿å­˜åˆ°: {output_file}")
        print(f"æ—¥å¿—ä¿å­˜åˆ°: logs/improved_gen_log.json")

def main():
    generator = ImprovedRCGenerator()
    generator.process_all_benchmarks(
        'benchmark/nl2code_java_F10L.jsonl',
        'benchmark/nl2code_java_F10L_improved_rc.jsonl'
    )

if __name__ == "__main__":
    main()
