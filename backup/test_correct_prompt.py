#!/usr/bin/env python3
"""
æµ‹è¯•æ­£ç¡®çš„prompté€»è¾‘
"""

import json
import re
import requests
from datetime import datetime

def test_correct_prompt():
    print("=== æµ‹è¯•æ­£ç¡®çš„prompté€»è¾‘ ===")
    
    # åŠ è½½ç¬¬ä¸€æ¡benchmark
    with open('benchmark/nl2code_java_F10L.jsonl', 'r', encoding='utf-8') as f:
        first_line = f.readline()
        benchmark = json.loads(first_line)
    
    # æå–ä¿¡æ¯
    context_above_match = re.search(r'The context above is:\s*```java\s*(.*?)\s*```', benchmark['prompt'], re.DOTALL)
    context_below_match = re.search(r'The context below is:\s*```java\s*(.*?)\s*```', benchmark['prompt'], re.DOTALL)
    task_match = re.search(r'The new feature is (.+?)\.', benchmark['prompt'])
    method_match = re.search(r'```java\s*(.*?)\s*```', benchmark['prompt'].split('And here is the code snippet you are asked to modify:')[1])
    
    current_code = f"{context_above_match.group(1).strip()}\n{context_below_match.group(1).strip()}"
    task = task_match.group(1).strip()
    new_method_signature = method_match.group(1).strip()
    new_method_implementation = benchmark['good_example_response'].replace('```java\n', '').replace('\n```', '').strip()
    
    # æ„é€ æœ€ç»ˆä»£ç çŠ¶æ€ï¼ˆæ’å…¥æ–°æ–¹æ³•åˆ°åˆé€‚ä½ç½®ï¼‰
    # åœ¨loadAndInvokeæ–¹æ³•ä¹‹åæ’å…¥æ–°æ–¹æ³•
    final_code = current_code.replace(
        '    }\n}',
        f'    }}\n\n{new_method_implementation}\n}}'
    )
    
    # åŠ è½½æ–°çš„promptæ¨¡æ¿
    with open('RC_prompt_v4_correct.txt', 'r', encoding='utf-8') as f:
        prompt_content = f.read()
    
    parts = prompt_content.split('(2) User Prompt')
    system_prompt = parts[0].replace('(1) System Prompt\n', '').strip()
    user_template = parts[1].strip()
    
    # æ„é€ ç”¨æˆ·prompt
    user_prompt = user_template.format(
        instruction=task,
        current_code=current_code,
        new_method_signature=new_method_signature,
        new_method_implementation=new_method_implementation,
        final_code_with_new_method=final_code
    )
    
    print("=== æ„é€ çš„promptå†…å®¹ ===")
    print("ä»»åŠ¡:", task)
    print("æ–°æ–¹æ³•ç­¾å:", new_method_signature)
    print("å½“å‰ä»£ç é•¿åº¦:", len(current_code))
    print("æœ€ç»ˆä»£ç é•¿åº¦:", len(final_code))
    print()
    
    # ä¿å­˜promptåˆ°æ–‡ä»¶
    with open('test_correct_prompt_content.txt', 'w', encoding='utf-8') as f:
        f.write("=== SYSTEM PROMPT ===\n")
        f.write(system_prompt)
        f.write("\n\n=== USER PROMPT ===\n")
        f.write(user_prompt)
    
    print("âœ… Promptå†…å®¹å·²ä¿å­˜åˆ°: test_correct_prompt_content.txt")
    
    # è°ƒç”¨LLMæµ‹è¯•
    api_key = "sk-q9fMcdnptLRU2oCLUN8JHORs4VS8rWJVqrwboB5SF8vrAyo8"
    api_url = "https://api2.aigcbest.top/v1/chat/completions"
    
    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json'
    }
    
    data = {
        'model': "gpt-4o-2024-08-06",
        'messages': [
            {'role': 'system', 'content': system_prompt},
            {'role': 'user', 'content': user_prompt}
        ],
        'temperature': 0.7,
        'max_tokens': 2500
    }
    
    try:
        print("\nğŸš€ è°ƒç”¨LLMæµ‹è¯•æ–°prompt...")
        response = requests.post(api_url, headers=headers, json=data, timeout=60)
        response.raise_for_status()
        result = response.json()
        llm_response = result['choices'][0]['message']['content']
        
        print("\n=== LLM Response ===")
        print(llm_response)
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        test_result = {
            'timestamp': datetime.now().isoformat(),
            'prompt_version': 'v4_correct',
            'task': task,
            'new_method_signature': new_method_signature,
            'system_prompt': system_prompt,
            'user_prompt': user_prompt,
            'llm_response': llm_response
        }
        
        with open('test_correct_prompt_result.json', 'w', encoding='utf-8') as f:
            json.dump(test_result, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: test_correct_prompt_result.json")
        
        # ç®€å•åˆ†æç»“æœ
        if 'loadClassWithApplicationLoader' in llm_response or 'Application' in llm_response:
            print("âœ… LLMå“åº”ä¸­æåˆ°äº†æ–°åŠŸèƒ½ç›¸å…³å†…å®¹")
        else:
            print("âŒ LLMå“åº”ä¸­æ²¡æœ‰æåˆ°æ–°åŠŸèƒ½ç›¸å…³å†…å®¹")
            
    except Exception as e:
        print(f"âŒ è°ƒç”¨å¤±è´¥: {e}")

if __name__ == "__main__":
    test_correct_prompt()
