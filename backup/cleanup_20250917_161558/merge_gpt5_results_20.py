#!/usr/bin/env python3
"""
åˆå¹¶GPT-5ç»“æœï¼ˆå10æ¡æ•°æ®ï¼‰å¹¶æ£€æŸ¥diffæ–¹å‘
"""

import json
import os
import re
from datetime import datetime

class GPT5ResultsMerger20:
    def __init__(self):
        self.gpt5_result_dir = "gpt5_result_20"
        self.gpt4o_template_dir = "final_gpt4o_output_20"
        self.output_dir = "gpt5_manual_20"
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)
    
    def read_gpt5_result(self, filename):
        """è¯»å–GPT-5ç»“æœæ–‡ä»¶"""
        filepath = os.path.join(self.gpt5_result_dir, filename)
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read().strip()
        return content
    
    def parse_hunks_from_gpt5(self, content):
        """è§£æGPT-5ç»“æœä¸­çš„hunks"""
        hunks_data = {}
        
        # æå–hunks_3, hunks_2, hunks_1
        for hunk_name in ['hunks_3', 'hunks_2', 'hunks_1']:
            # åŒ¹é…å„ç§å¯èƒ½çš„æ ¼å¼ï¼ŒåŒ…æ‹¬è½¬ä¹‰ç¬¦
            escaped_name = hunk_name.replace('_', r'\\_')
            patterns = [
                rf'### {escaped_name}.*?```json\s*(.*?)\s*```',
                rf'### {hunk_name}.*?```json\s*(.*?)\s*```',
                rf'## {escaped_name}.*?```json\s*(.*?)\s*```',
                rf'## {hunk_name}.*?```json\s*(.*?)\s*```',
                rf'{escaped_name}.*?```json\s*(.*?)\s*```',
                rf'{hunk_name}.*?```json\s*(.*?)\s*```'
            ]
            
            found = False
            for pattern in patterns:
                match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
                if match:
                    try:
                        json_content = match.group(1).strip()
                        # æ¸…ç†å¯èƒ½çš„è½¬ä¹‰å­—ç¬¦
                        json_content = json_content.replace('\\_', '_')
                        hunks_list = json.loads(json_content)
                        hunks_data[hunk_name] = hunks_list
                        found = True
                        print(f"  âœ… æˆåŠŸè§£æ {hunk_name}: {len(hunks_list)} ä¸ªhunks")
                        break
                    except json.JSONDecodeError as e:
                        print(f"  âš ï¸ è§£æ{hunk_name}å¤±è´¥: {e}")
                        continue
            
            if not found:
                print(f"  âŒ æœªæ‰¾åˆ° {hunk_name}")
                hunks_data[hunk_name] = []
        
        return hunks_data
    
    def check_diff_direction(self, hunks_data, final_code_lines):
        """æ£€æŸ¥diffæ–¹å‘æ˜¯å¦æ­£ç¡®"""
        fix_info = []
        total_fixes = 0
        
        for hunk_name, hunks_list in hunks_data.items():
            for i, hunk in enumerate(hunks_list):
                diff_content = hunk.get('diff_content', '')
                if not diff_content:
                    continue
                
                # è§£ædiffå†…å®¹
                lines = diff_content.split('\\n')
                fixed_lines = []
                hunk_fixes = 0
                
                for line in lines:
                    if line.startswith('+') and len(line) > 1:
                        # æ£€æŸ¥+è¡Œå†…å®¹æ˜¯å¦åœ¨æœ€ç»ˆä»£ç ä¸­å­˜åœ¨
                        line_content = line[1:].strip()
                        # æå–è¡Œå·ï¼ˆå¦‚æœæœ‰ï¼‰
                        line_match = re.match(r'\s*(\d+):\s*(.*)', line_content)
                        if line_match:
                            line_num = int(line_match.group(1))
                            actual_content = line_match.group(2)
                            
                            # æ£€æŸ¥æ˜¯å¦åœ¨æœ€ç»ˆä»£ç ä¸­
                            if line_num <= len(final_code_lines):
                                final_line = final_code_lines[line_num - 1].strip()
                                if actual_content not in final_line:
                                    print(f"  âš ï¸ {hunk_name}[{i}]: +è¡Œå†…å®¹ä¸åœ¨æœ€ç»ˆä»£ç ä¸­")
                                    print(f"    æœŸæœ›: {actual_content}")
                                    print(f"    å®é™…: {final_line}")
                        
                        fixed_lines.append(line)
                        
                    elif line.startswith('-') and len(line) > 1:
                        # æ£€æŸ¥-è¡Œå†…å®¹æ˜¯å¦åœ¨æœ€ç»ˆä»£ç ä¸­å­˜åœ¨
                        line_content = line[1:].strip()
                        line_match = re.match(r'\s*(\d+):\s*(.*)', line_content)
                        if line_match:
                            line_num = int(line_match.group(1))
                            actual_content = line_match.group(2)
                            
                            # æ£€æŸ¥æ˜¯å¦åœ¨æœ€ç»ˆä»£ç ä¸­
                            if line_num <= len(final_code_lines):
                                final_line = final_code_lines[line_num - 1].strip()
                                if actual_content in final_line:
                                    # åœ¨æœ€ç»ˆä»£ç ä¸­å­˜åœ¨ï¼Œåº”è¯¥æ˜¯+
                                    fixed_line = '+' + line[1:]
                                    fixed_lines.append(fixed_line)
                                    hunk_fixes += 1
                                    total_fixes += 1
                                    print(f"  ğŸ”§ {hunk_name}[{i}]: ä¿®å¤æ–¹å‘ - â†’ +")
                                else:
                                    # ä¸åœ¨æœ€ç»ˆä»£ç ä¸­ï¼Œç¡®å®åº”è¯¥åˆ é™¤
                                    fixed_lines.append(line)
                            else:
                                fixed_lines.append(line)
                        else:
                            fixed_lines.append(line)
                    else:
                        fixed_lines.append(line)
                
                # æ›´æ–°diffå†…å®¹
                if hunk_fixes > 0:
                    hunk['diff_content'] = '\\n'.join(fixed_lines)
                    fix_info.append(f"{hunk_name}[{i}]: {hunk_fixes}ä¸ªä¿®å¤")
        
        return total_fixes, fix_info
    
    def merge_single_file(self, benchmark_id):
        """åˆå¹¶å•ä¸ªæ–‡ä»¶"""
        print(f"ğŸ”„ å¤„ç† {benchmark_id}...")
        
        # è¯»å–GPT-5ç»“æœ
        gpt5_filename = f"{benchmark_id}.txt"
        gpt5_content = self.read_gpt5_result(gpt5_filename)
        
        # è¯»å–GPT-4oæ¨¡æ¿
        gpt4o_filename = f"{benchmark_id}.json"
        gpt4o_filepath = os.path.join(self.gpt4o_template_dir, gpt4o_filename)
        
        with open(gpt4o_filepath, 'r', encoding='utf-8') as f:
            gpt4o_data = json.load(f)
        
        # è§£æGPT-5çš„hunks
        hunks_data = self.parse_hunks_from_gpt5(gpt5_content)
        
        # æ£€æŸ¥diffæ–¹å‘
        final_code_lines = gpt4o_data.get('final_code_with_annotations', '').split('\n')
        total_fixes, fix_info = self.check_diff_direction(hunks_data, final_code_lines)
        
        # åˆ›å»ºåˆå¹¶åçš„æ•°æ®
        merged_data = {
            'benchmark_id': benchmark_id,
            'timestamp': datetime.now().isoformat(),
            'model_used': 'gpt-5-manual-20',
            'prompt_version': 'v9_improved',
            'selected_region': gpt4o_data.get('selected_region', ''),
            'target_implementation': gpt4o_data.get('target_implementation', ''),
            'final_code_with_annotations': gpt4o_data.get('final_code_with_annotations', ''),
            'prompt': gpt4o_data.get('prompt', {}),
            'llm_response': gpt5_content,
            'parsed_hunks': hunks_data,
            'validation_results': gpt4o_data.get('validation_results', {}),
            'fix_info': {
                'total_fixes': total_fixes,
                'fix_details': fix_info,
                'fixed_at': datetime.now().isoformat()
            },
            'original_benchmark': gpt4o_data.get('original_benchmark', {})
        }
        
        # ä¿å­˜åˆå¹¶ç»“æœ
        output_filepath = os.path.join(self.output_dir, f"{benchmark_id}.json")
        with open(output_filepath, 'w', encoding='utf-8') as f:
            json.dump(merged_data, f, ensure_ascii=False, indent=2)
        
        if total_fixes > 0:
            print(f"  ğŸ”§ {benchmark_id}: ä¿®å¤äº† {total_fixes} ä¸ªdiffæ–¹å‘é—®é¢˜")
        else:
            print(f"  âœ… {benchmark_id}: diffæ–¹å‘æ­£ç¡®ï¼Œæ— éœ€ä¿®å¤")
        
        return {
            'benchmark_id': benchmark_id,
            'hunks_count': [len(hunks_data.get('hunks_3', [])), 
                           len(hunks_data.get('hunks_2', [])), 
                           len(hunks_data.get('hunks_1', []))],
            'fixes_applied': total_fixes
        }
    
    def merge_all_files(self):
        """åˆå¹¶æ‰€æœ‰æ–‡ä»¶"""
        print("=== å¼€å§‹åˆå¹¶GPT-5ç»“æœï¼ˆå10æ¡æ•°æ®ï¼‰===")
        
        # è·å–æ‰€æœ‰txtæ–‡ä»¶
        txt_files = [f for f in os.listdir(self.gpt5_result_dir) if f.endswith('.txt')]
        
        results = []
        total_fixes = 0
        
        for txt_file in sorted(txt_files):
            benchmark_id = txt_file[:-4]  # ç§»é™¤.txtåç¼€
            result = self.merge_single_file(benchmark_id)
            results.append(result)
            total_fixes += result['fixes_applied']
        
        # ä¿å­˜æ‘˜è¦
        summary = {
            'timestamp': datetime.now().isoformat(),
            'model_used': 'gpt-5-manual-20',
            'prompt_version': 'v9_improved',
            'total_benchmarks': len(results),
            'total_fixes_applied': total_fixes,
            'results': results
        }
        
        summary_filepath = os.path.join(self.output_dir, 'gpt5_manual_20_summary.json')
        with open(summary_filepath, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ‰ åˆå¹¶å®Œæˆï¼")
        print(f"å¤„ç†æ–‡ä»¶æ•°: {len(results)}")
        print(f"æ€»ä¿®å¤æ•°: {total_fixes}")
        print(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        
        return summary

if __name__ == "__main__":
    merger = GPT5ResultsMerger20()
    summary = merger.merge_all_files()
