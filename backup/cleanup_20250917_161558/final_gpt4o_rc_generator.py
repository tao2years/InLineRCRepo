#!/usr/bin/env python3
"""
æœ€ç»ˆGPT-4o RCç”Ÿæˆå™¨ - ä½¿ç”¨æœ€æ–°promptå’Œä¼˜åŒ–çš„APIè°ƒç”¨
"""

import json
import requests
import os
import re
import time
from datetime import datetime

class FinalGPT4oRCGenerator:
    def __init__(self):
        self.api_key = "sk-q9fMcdnptLRU2oCLUN8JHORs4VS8rWJVqrwboB5SF8vrAyo8"
        self.api_url = "https://api2.aigcbest.top/v1/chat/completions"
        self.model = "gpt-4o-2024-11-20"  # ä½¿ç”¨æœ€æ–°çš„GPT-4o
        self.output_dir = "final_gpt4o_output_20"
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)
        
        # åŠ è½½æœ€æ–°çš„promptæ¨¡æ¿
        self.system_prompt, self.user_prompt_template = self.load_prompt_template()
        
    def load_prompt_template(self):
        """åŠ è½½æœ€æ–°çš„promptæ¨¡æ¿"""
        with open('RC_prompt_v8_gpt5.txt', 'r', encoding='utf-8') as f:
            content = f.read()
        parts = content.split('(2) User Prompt')
        system_prompt = parts[0].replace('(1) System Prompt\n', '').strip()
        user_template = parts[1].strip()
        return system_prompt, user_template
    
    def parse_benchmark(self, benchmark):
        """è§£æbenchmarkæ•°æ®"""
        # æå–åŸºæœ¬ä¿¡æ¯
        benchmark_id = benchmark.get('id', 'unknown')
        
        # ä»promptå­—ç¬¦ä¸²ä¸­æå–context
        prompt_text = benchmark.get('prompt', '')
        
        # è§£æcontext_above
        context_above_match = re.search(r'The context above is:\s*```java\s*(.*?)\s*```', prompt_text, re.DOTALL)
        context_above = context_above_match.group(1) if context_above_match else ''
        
        # è§£æcontext_below
        context_below_match = re.search(r'The context below is:\s*```java\s*(.*?)\s*```', prompt_text, re.DOTALL)
        context_below = context_below_match.group(1) if context_below_match else ''
        
        # è§£æé€‰ä¸­åŒºåŸŸ
        selected_match = re.search(r'And here is the code snippet you are asked to modify:\s*```java\s*(.*?)\s*```', prompt_text, re.DOTALL)
        selected_region = selected_match.group(1).strip() if selected_match else ''
        
        # ç›®æ ‡å®ç°
        good_example = benchmark.get('good_example_response', '')
        # æ¸…ç†good_exampleä¸­çš„```javaæ ‡è®°
        target_implementation = re.sub(r'```java\s*|\s*```', '', good_example).strip()
        
        # å®Œæ•´ä»£ç  = context_above + target_implementation + context_below
        full_code = context_above + '\n' + target_implementation + '\n' + context_below
        
        return {
            'benchmark_id': benchmark_id,
            'full_code': full_code,
            'selected_region': selected_region,
            'target_implementation': target_implementation
        }
    
    def add_line_numbers_with_annotations(self, code_content, selected_region, target_implementation):
        """æ·»åŠ è¡Œå·å’Œæ­£ç¡®çš„ç¦æ­¢ä¿®æ”¹æ ‡æ³¨"""
        lines = code_content.split('\n')
        numbered_lines = []
        
        # æ‰¾åˆ°ç›®æ ‡å®ç°çš„è¡Œå·èŒƒå›´
        target_lines = set()
        if target_implementation.strip():
            # æ¸…ç†ç›®æ ‡å®ç°å†…å®¹
            clean_target = target_implementation.replace('```java\n', '').replace('\n```', '').strip()
            target_lines_content = clean_target.split('\n')
            
            # æ‰¾åˆ°ç›®æ ‡å®ç°çš„å¼€å§‹è¡Œ
            first_target_line = target_lines_content[0].strip()
            target_start_line = None
            
            for i, line in enumerate(lines):
                if first_target_line in line.strip():
                    target_start_line = i + 1  # è¡Œå·ä»1å¼€å§‹
                    break
            
            if target_start_line:
                # è®¡ç®—ç›®æ ‡å®ç°çš„å®Œæ•´è¡Œå·èŒƒå›´
                for j in range(len(target_lines_content)):
                    if target_start_line + j <= len(lines):
                        target_lines.add(target_start_line + j)
        
        # ç”Ÿæˆå¸¦è¡Œå·å’Œæ ‡æ³¨çš„ä»£ç 
        for i, line in enumerate(lines):
            line_number = i + 1
            if line_number in target_lines:
                numbered_lines.append(f"{line_number:3d}: {line} // [ç¦æ­¢ä¿®æ”¹-ç›®æ ‡å®ç°]")
            else:
                numbered_lines.append(f"{line_number:3d}: {line}")
        
        return '\n'.join(numbered_lines)
    
    def create_prompt(self, parsed_data):
        """åˆ›å»ºä¼˜åŒ–çš„prompt"""
        # æ·»åŠ è¡Œå·å’Œæ ‡æ³¨
        final_code_with_annotations = self.add_line_numbers_with_annotations(
            parsed_data['full_code'],
            parsed_data['selected_region'],
            parsed_data['target_implementation']
        )
        
        # å¡«å……ç”¨æˆ·promptæ¨¡æ¿ï¼ˆç§»é™¤TASK_DESCRIPTIONï¼‰
        user_prompt = self.user_prompt_template.format(
            selected_region=parsed_data['selected_region'],
            target_implementation=parsed_data['target_implementation'],
            final_code_with_annotations=final_code_with_annotations
        )
        
        return {
            'system_prompt': self.system_prompt,
            'user_prompt': user_prompt,
            'final_code_with_annotations': final_code_with_annotations
        }
    
    def call_gpt4o_api(self, system_prompt, user_prompt, max_retries=3):
        """è°ƒç”¨GPT-4o API - ä¼˜åŒ–çš„é‡è¯•æœºåˆ¶"""
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': self.model,
            'messages': [
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_prompt}
            ],
            'temperature': 0.7,
            'max_tokens': 3000
        }
        
        for attempt in range(max_retries):
            timeout = 30 + attempt * 15  # 30s, 45s, 60s
            
            try:
                print(f"  APIè°ƒç”¨ (è¶…æ—¶: {timeout}ç§’, å°è¯•: {attempt + 1}/{max_retries})...")
                response = requests.post(self.api_url, headers=headers, json=data, timeout=timeout)
                
                if response.status_code == 200:
                    result = response.json()
                    if 'choices' in result and len(result['choices']) > 0:
                        content = result['choices'][0]['message']['content']
                        usage = result.get('usage', {})
                        print(f"  âœ… APIè°ƒç”¨æˆåŠŸ (å“åº”é•¿åº¦: {len(content)} å­—ç¬¦)")
                        return content, usage
                    else:
                        print(f"  âŒ å“åº”æ ¼å¼é”™è¯¯: {result}")
                        
                elif response.status_code == 429:
                    print(f"  âš ï¸ é€Ÿç‡é™åˆ¶ (429)")
                    if attempt < max_retries - 1:
                        print(f"  ç­‰å¾… 5 ç§’åé‡è¯•...")
                        time.sleep(5)
                    continue
                    
                elif response.status_code >= 500:
                    print(f"  âš ï¸ æœåŠ¡å™¨é”™è¯¯ {response.status_code}")
                    
                else:
                    print(f"  âŒ HTTPé”™è¯¯ {response.status_code}: {response.text[:100]}")
                    
            except requests.exceptions.Timeout:
                print(f"  âš ï¸ è¯·æ±‚è¶…æ—¶ ({timeout}ç§’)")
                
            except requests.exceptions.ConnectionError:
                print(f"  âš ï¸ è¿æ¥é”™è¯¯")
                
            except Exception as e:
                print(f"  âŒ APIè°ƒç”¨å¼‚å¸¸: {e}")
            
            # é‡è¯•ç­‰å¾…
            if attempt < max_retries - 1:
                wait_time = 2  # å›ºå®š2ç§’ç­‰å¾…
                print(f"  ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
        
        print(f"  âŒ APIè°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡")
        return None, {}
    
    def parse_hunks_response(self, response_text):
        """è§£æhunkså“åº”"""
        hunks_data = {}
        
        # æå–hunks_3, hunks_2, hunks_1
        for hunk_name in ['hunks_3', 'hunks_2', 'hunks_1']:
            pattern = rf'### {hunk_name}.*?```json\s*(.*?)\s*```'
            match = re.search(pattern, response_text, re.DOTALL | re.IGNORECASE)
            
            if match:
                try:
                    json_content = match.group(1).strip()
                    hunks_list = json.loads(json_content)
                    hunks_data[hunk_name] = hunks_list
                except json.JSONDecodeError as e:
                    print(f"  è§£æ{hunk_name}å¤±è´¥: {e}")
                    hunks_data[hunk_name] = []
            else:
                print(f"  æœªæ‰¾åˆ°{hunk_name}")
                hunks_data[hunk_name] = []
        
        return hunks_data
    
    def validate_line_numbers(self, hunks_data, final_code_lines):
        """éªŒè¯è¡Œå·æœ‰æ•ˆæ€§"""
        total_lines = len(final_code_lines)
        validation_issues = 0
        
        for hunk_name, hunks_list in hunks_data.items():
            for hunk in hunks_list:
                start_line = hunk.get('start_line', 0)
                end_line = hunk.get('end_line', 0)
                
                if start_line < 1 or start_line > total_lines:
                    print(f"  âš ï¸ {hunk_name}: start_line {start_line} è¶…å‡ºèŒƒå›´ [1, {total_lines}]")
                    validation_issues += 1
                
                if end_line < 1 or end_line > total_lines:
                    print(f"  âš ï¸ {hunk_name}: end_line {end_line} è¶…å‡ºèŒƒå›´ [1, {total_lines}]")
                    validation_issues += 1
                
                if start_line > end_line:
                    print(f"  âš ï¸ {hunk_name}: start_line {start_line} > end_line {end_line}")
                    validation_issues += 1
        
        return validation_issues

    def process_single_benchmark(self, benchmark, index):
        """å¤„ç†å•ä¸ªbenchmark"""
        parsed_data = self.parse_benchmark(benchmark)
        benchmark_id = parsed_data['benchmark_id']

        print(f"ğŸš€ å¤„ç† {benchmark_id}...")

        # åˆ›å»ºprompt
        prompt_data = self.create_prompt(parsed_data)

        # è°ƒç”¨GPT-4o API
        llm_response, usage = self.call_gpt4o_api(
            prompt_data['system_prompt'],
            prompt_data['user_prompt']
        )

        if llm_response:
            # è§£æå“åº”
            hunks_data = self.parse_hunks_response(llm_response)

            # éªŒè¯è¡Œå·
            final_code_lines = prompt_data['final_code_with_annotations'].split('\n')
            validation_issues = self.validate_line_numbers(hunks_data, final_code_lines)

            # ä¿å­˜å®Œæ•´ç»“æœ
            complete_result = {
                'benchmark_id': benchmark_id,
                'timestamp': datetime.now().isoformat(),
                'model_used': self.model,
                'selected_region': parsed_data['selected_region'],
                'target_implementation': parsed_data['target_implementation'],
                'final_code_with_annotations': prompt_data['final_code_with_annotations'],
                'prompt': {
                    'system_prompt': prompt_data['system_prompt'],
                    'user_prompt': prompt_data['user_prompt']
                },
                'llm_response': llm_response,
                'parsed_hunks': hunks_data,
                'validation_results': {
                    'total_issues': validation_issues,
                    'total_lines': len(final_code_lines)
                },
                'usage': usage,
                'original_benchmark': benchmark
            }

            # ä¿å­˜åˆ°æ–‡ä»¶
            output_file = os.path.join(self.output_dir, f"{benchmark_id}.json")
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(complete_result, f, ensure_ascii=False, indent=2)

            if validation_issues == 0:
                print(f"âœ… {benchmark_id} å¤„ç†æˆåŠŸï¼Œè¡Œå·éªŒè¯é€šè¿‡")
            else:
                print(f"âš ï¸ {benchmark_id} å¤„ç†æˆåŠŸï¼Œä½†æœ‰ {validation_issues} ä¸ªéªŒè¯é—®é¢˜")

            return {
                'benchmark_id': benchmark_id,
                'status': 'success',
                'hunks_count': [len(hunks_data.get('hunks_3', [])),
                               len(hunks_data.get('hunks_2', [])),
                               len(hunks_data.get('hunks_1', []))],
                'validation_issues': validation_issues
            }

        print(f"âŒ {benchmark_id} å¤„ç†å¤±è´¥")
        return {
            'benchmark_id': benchmark_id,
            'status': 'failed',
            'hunks_count': [0, 0, 0],
            'validation_issues': 0
        }

    def generate_all_final(self):
        """ç”Ÿæˆæ‰€æœ‰benchmarkçš„æœ€ç»ˆRC"""
        print("=== å¼€å§‹æœ€ç»ˆGPT-4o RCç”Ÿæˆï¼ˆæœ€æ–°promptï¼‰ ===")
        print(f"ä½¿ç”¨æ¨¡å‹: {self.model}")

        # åŠ è½½benchmarkæ•°æ®
        with open('benchmark/nl2code_java_F20L.jsonl', 'r', encoding='utf-8') as f:
            benchmarks = [json.loads(line) for line in f]

        print(f"æ€»benchmarkæ•°: {len(benchmarks)}")

        results = []
        successful_count = 0
        failed_count = 0

        for i, benchmark in enumerate(benchmarks, 1):
            print(f"\n--- å¤„ç†ç¬¬ {i}/{len(benchmarks)} ä¸ªbenchmark ---")
            result = self.process_single_benchmark(benchmark, i)
            results.append(result)

            if result['status'] == 'success':
                successful_count += 1
                print(f"âœ… æˆåŠŸ: {successful_count}, å¤±è´¥: {failed_count}")
            else:
                failed_count += 1
                print(f"âŒ æˆåŠŸ: {successful_count}, å¤±è´¥: {failed_count}")

            # æ¯å¤„ç†5ä¸ªä¿å­˜ä¸€æ¬¡è¿›åº¦
            if i % 5 == 0:
                self.save_progress_summary(results, i, len(benchmarks))

        # ä¿å­˜æœ€ç»ˆç»“æœ
        final_summary = self.save_progress_summary(results, len(benchmarks), len(benchmarks), is_final=True)

        print(f"\nğŸ‰ æœ€ç»ˆGPT-4oç”Ÿæˆå®Œæˆï¼")
        print(f"æ¨¡å‹: {self.model}")
        print(f"æˆåŠŸ: {final_summary['successful']}/{final_summary['total_benchmarks']}")
        print(f"å¤±è´¥: {final_summary['failed']}/{final_summary['total_benchmarks']}")
        print(f"éªŒè¯é—®é¢˜æ€»æ•°: {final_summary['total_validation_issues']}")

        return final_summary

    def save_progress_summary(self, results, current, total, is_final=False):
        """ä¿å­˜è¿›åº¦æ‘˜è¦"""
        summary = {
            'timestamp': datetime.now().isoformat(),
            'model_used': self.model,
            'progress': f"{current}/{total}",
            'total_benchmarks': total,
            'processed': current,
            'successful': len([r for r in results if r['status'] == 'success']),
            'failed': len([r for r in results if r['status'] == 'failed']),
            'total_validation_issues': sum([r.get('validation_issues', 0) for r in results]),
            'results': results
        }

        filename = 'final_gpt4o_summary.json' if is_final else 'final_gpt4o_progress.json'
        with open(f'{self.output_dir}/{filename}', 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)

        if not is_final:
            print(f"ğŸ“Š è¿›åº¦å·²ä¿å­˜: {current}/{total}")

        return summary

if __name__ == "__main__":
    generator = FinalGPT4oRCGenerator()

    print("=== å¯åŠ¨æœ€ç»ˆGPT-4oæ‰¹é‡ç”Ÿæˆ ===")
    print(f"ä½¿ç”¨æ¨¡å‹: {generator.model}")

    # å¼€å§‹æ‰¹é‡å¤„ç†
    summary = generator.generate_all_final()

    print(f"\nğŸ‰ æ‰¹é‡ç”Ÿæˆå®Œæˆï¼")
    print(f"æœ€ç»ˆç»“æœ: æˆåŠŸ {summary['successful']}/{summary['total_benchmarks']}")
