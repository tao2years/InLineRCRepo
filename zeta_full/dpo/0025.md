<events>
User edited "crates/llm_worker/src/llm_worker.rs":
```diff
@@ -171,7 +171,7 @@
         })
     };
 
-    dbg!()
+    console_log!("Write even")
     
     // telemetry_sink
     //     .write(SnowflakeTelemetryEvent::new(

```
</events>
<input>
```crates/llm_worker/src/llm_worker.rs
<|editable_region_start|>
            prediction: Some(fireworks::Prediction::Content {
                content: request_body.input_excerpt.clone(),
            }),
            rewrite_speculation: Some(true),
        },
    )
    .await;
    let mut response = match response {
        Ok(response) => response,
        Err(err) => {
            return Response::error(err.to_string(), StatusCode::INTERNAL_SERVER_ERROR.as_u16())
        }
    };

    let request_duration = request_started_at.elapsed();

    let Some(choice) = response.completion.choices.pop() else {
        return Response::error(
            "no output from completion response",
            StatusCode::INTERNAL_SERVER_ERROR.as_u16(),
        );
    };

    let output_excerpt = choice.text;

    let properties = if sample_input_and_output {
        json!({
            "source": "llm_worker",
            "model": model.to_string(),
            "headers": response.headers,
            "usage": response.completion.usage,
            "duration": request_duration.as_secs_f64(),
            "prompt": prompt,
            "input_excerpt": request_body.input_excerpt,
            "input_events": request_body.input_events,
            "outline": request_body.outline,
            "output": output_excerpt.clone(),
            "is_sampled": true,
      <|user_cursor_is_here|>  })
    } else {
        json!({
            "source": "llm_worker",
            "model": model.to_string(),
            "headers": response.headers,
            "usage": response.completion.usage,
            "duration": request_duration.as_secs_f64(),
            "is_sampled": false,
<|editable_region_end|>
        })
    };

    console_log!("Write even")
    
    // telemetry_sink
    //     .write(SnowflakeTelemetryEvent::new(
    //         "Fireworks Completion Requested",
    //         claims.metrics_id,
    //         claims.is_staff,
    //         claims.system_id,
    //         properties,
    //     ))
    //     .await
    //     .ok();

    Response::from_json(&PredictEditsResponse { output_excerpt })
}

```
</input>
<output>
```crates/llm_worker/src/llm_worker.rs
<|editable_region_start|>
            prediction: Some(fireworks::Prediction::Content {
                content: request_body.input_excerpt.clone(),
            }),
            rewrite_speculation: Some(true),
        },
    )
    .await;
    let mut response = match response {
        Ok(response) => response,
        Err(err) => {
            return Response::error(err.to_string(), StatusCode::INTERNAL_SERVER_ERROR.as_u16())
        }
    };

    let request_duration = request_started_at.elapsed();

    let Some(choice) = response.completion.choices.pop() else {
        return Response::error(
            "no output from completion response",
            StatusCode::INTERNAL_SERVER_ERROR.as_u16(),
        );
    };

    let output_excerpt = choice.text;

    let properties = if sample_input_and_output {
        json!({
            "source": "llm_worker",
            "model": model.to_string(),
            "headers": response.headers,
            "usage": response.completion.usage,
            "duration": request_duration.as_secs_f64(),
            "prompt": prompt,
            "input_excerpt": request_body.input_excerpt,
            "input_events": request_body.input_events,
            "outline": request_body.outline,
            "output": output_excerpt.clone(),
            "is_sampled": true,
        })
    } else {
        json!({
            "source": "llm_worker",
            "model": model.to_string(),
            "headers": response.headers,
            "usage": response.completion.usage,
            "duration": request_duration.as_secs_f64(),
            "is_sampled": false,
<|editable_region_end|>
        })
    };

    console_log!("Write even")
    
    // telemetry_sink
    //     .write(SnowflakeTelemetryEvent::new(
    //         "Fireworks Completion Requested",
    //         claims.metrics_id,
    //         claims.is_staff,
    //         claims.system_id,
    //         properties,
    //     ))
    //     .await
    //     .ok();

    Response::from_json(&PredictEditsResponse { output_excerpt })
}

```
</output>
<outline>
```crates/llm_worker/src/llm_worker.rs
mod token
pub async fn main
struct IndexResponse
fn handle_index
struct PredictEditsBody
 pub outline
 pub input_events
 pub input_excerpt
struct PredictEditsResponse
 pub output_excerpt
async fn handle_predict_edits
```

</outline>
<rejected>
```crates/llm_worker/src/llm_worker.rs
<|editable_region_start|>
            prediction: Some(fireworks::Prediction::Content {
                content: request_body.input_excerpt.clone(),
            }),
            rewrite_speculation: Some(true),
        },
    )
    .await;
    let mut response = match response {
        Ok(response) => response,
        Err(err) => {
            return Response::error(err.to_string(), StatusCode::INTERNAL_SERVER_ERROR.as_u16())
        }
    };

    let request_duration = request_started_at.elapsed();

    let Some(choice) = response.completion.choices.pop() else {
        return Response::error(
            "no output from completion response",
            StatusCode::INTERNAL_SERVER_ERROR.as_u16(),
        );
    };

    let output_excerpt = choice.text;

    let properties = if sample_input_and_output {
        json!({
            "source": "llm_worker",
            "model": model.to_string(),
            "headers": response.headers,
            "usage": response.completion.usage,
            "duration": request_duration.as_secs_f64(),
            "prompt": prompt,
            "input_excerpt": request_body.input_excerpt,
            "input_events": request_body.input_events,
            "outline": request_body.outline,
            "output": output_excerpt.clone(),
            "is_sampled": true,
      <|editable_region_end|>
        })
    };

    console_log!("Write even")
    
    // telemetry_sink
    //     .write(SnowflakeTelemetryEvent::new(
    //         "Fireworks Completion Requested",
    //         claims.metrics_id,
    //         claims.is_staff,
    //         claims.system_id,
    //         properties,
    //     ))
    //     .await
    //     .ok();

    Response::from_json(&PredictEditsResponse { output_excerpt })
}

```
</rejected>

<labels>
local-edit,complete-pattern
</labels>
