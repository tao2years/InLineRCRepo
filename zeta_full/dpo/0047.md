<events>
User edited "crates/zeta/src/zeta.rs":
```diff
@@ -543,9 +543,6 @@
             loop {
                 let request_builder = http_client::Request::builder().method(Method::POST);
                 let request_builder = if is_staff {
-                        // Start dogfooding the new LLM worker for staff edit predictions.
-                        // 
-                        // 
                     request_builder.uri(
                         "https://llm-worker-production.zed-industries.workers.dev/predict_edits",
                     )

```

User edited "crates/llm_worker/src/llm_worker.rs":
```diff
@@ -17,6 +17,10 @@
         .await
 }
 
+struct Config {
+    
+}
+
 #[derive(Debug, Serialize, Deserialize)]
 struct IndexResponse {}
 

```



User edited "crates/llm_worker/src/llm_worker.rs":
```diff
@@ -17,10 +17,6 @@
         .await
 }
 
-struct Config {
-    
-}
-
 #[derive(Debug, Serialize, Deserialize)]
 struct IndexResponse {}
 

```

User edited "crates/llm_worker/src/llm_worker.rs":
```diff
@@ -36,6 +36,8 @@
     pub output_excerpt: String,
 }
 
+fn v
+
 async fn handle_predict_edits(mut req: Request, cx: RouteContext<()>) -> Result<Response> {
     let Some(authorization) = req.headers().get("authorization")? else {
         return Response::error(

```
</events>
<input>
```crates/llm_worker/src/llm_worker.rs
use telemetry_sink::{SnowflakeTelemetryEvent, SnowflakeTelemetrySink};
<|editable_region_start|>
use worker::*;

use crate::token::{LlmTokenClaims, LlmTokenSecret, ValidateLlmTokenError};

#[event(fetch)]
pub async fn main(req: Request, env: Env, _cx: worker::Context) -> Result<Response> {
    Router::new()
        .get("/", handle_index)
        .post_async("/predict_edits", handle_predict_edits)
        .run(req, env)
        .await
}

#[derive(Debug, Serialize, Deserialize)]
struct IndexResponse {}

fn handle_index(_req: Request, _cx: RouteContext<()>) -> Result<Response> {
    Response::from_json(&IndexResponse {})
}

#[derive(Debug, Deserialize)]
struct PredictEditsBody {
    pub outline: Option<String>,
    pub input_events: String,
    pub input_excerpt: String,
}

#[derive(Debug, Serialize)]
struct PredictEditsResponse {
    pub output_excerpt: String,
}

fn v<|user_cursor_is_here|>

async fn handle_predict_edits(mut req: Request, cx: RouteContext<()>) -> Result<Response> {
    let Some(authorization) = req.headers().get("authorization")? else {
        return Response::error(
            StatusCode::UNAUTHORIZED.as_str(),
            StatusCode::UNAUTHORIZED.as_u16(),
        );
    };

    let parts = authorization.split_whitespace().collect::<Vec<_>>();
    if parts.len() != 2 || parts[0].to_lowercase() != "bearer" {
        return Response::error(
            "Invalid authorization header",
            StatusCode::UNAUTHORIZED.as_u16(),
        );
    }

    let token = parts[1];

    let llm_token_secret = LlmTokenSecret(cx.secret("LLM_API_SECRET")?.to_string());

    let claims = match LlmTokenClaims::validate(token, &llm_token_secret) {
        Ok(claims) => claims,
        Err(err) => match err {
            ValidateLlmTokenError::Expired => {
                return Ok(Response::builder()
                    .with_status(StatusCode::UNAUTHORIZED.as_u16())
                    .with_header("x-zed-expired-token", "true")?
                    .fixed(StatusCode::UNAUTHORIZED.as_str().as_bytes().to_vec()))
            }
            ValidateLlmTokenError::JwtParseError(_)
            | ValidateLlmTokenError::JwtValidationError(_)
<|editable_region_end|>
            | ValidateLlmTokenError::Other(_) => {
```
</input>
<output>
```crates/llm_worker/src/llm_worker.rs
use telemetry_sink::{SnowflakeTelemetryEvent, SnowflakeTelemetrySink};
<|editable_region_start|>
use worker::*;

use crate::token::{LlmTokenClaims, LlmTokenSecret, ValidateLlmTokenError};

#[event(fetch)]
pub async fn main(req: Request, env: Env, _cx: worker::Context) -> Result<Response> {
    Router::new()
        .get("/", handle_index)
        .post_async("/predict_edits", handle_predict_edits)
        .run(req, env)
        .await
}

#[derive(Debug, Serialize, Deserialize)]
struct IndexResponse {}

fn handle_index(_req: Request, _cx: RouteContext<()>) -> Result<Response> {
    Response::from_json(&IndexResponse {})
}

#[derive(Debug, Deserialize)]
struct PredictEditsBody {
    pub outline: Option<String>,
    pub input_events: String,
    pub input_excerpt: String,
}

#[derive(Debug, Serialize)]
struct PredictEditsResponse {
    pub output_excerpt: String,
}

fn validate_request(req: &Request, cx: &RouteContext<()>) -> Result<LlmTokenClaims> {
    let Some(authorization) = req.headers().get("authorization")? else {
        return Err(Error::from(Response::error(
            StatusCode::UNAUTHORIZED.as_str(),
            StatusCode::UNAUTHORIZED.as_u16(),
        )));
    };

    let parts = authorization.split_whitespace().collect::<Vec<_>>();
    if parts.len() != 2 || parts[0].to_lowercase() != "bearer" {
        return Err(Error::from(Response::error(
            "Invalid authorization header",
            StatusCode::UNAUTHORIZED.as_u16(),
        )));
    }

    let token = parts[1];
    let llm_token_secret = LlmTokenSecret(cx.secret("LLM_API_SECRET")?.to_string());

    match LlmTokenClaims::validate(token, &llm_token_secret) {
        Ok(claims) => Ok(claims),
        Err(ValidateLlmTokenError::Expired) => {
            Err(Error::from(Response::builder()
                .with_status(StatusCode::UNAUTHORIZED.as_u16())
                .with_header("x-zed-expired-token", "true")?
                .fixed(StatusCode::UNAUTHORIZED.as_str().as_bytes().to_vec())))
        }
        Err(err) => Err(Error::from(Response::error(
            format!("Failed to validate token: {}", err),
            StatusCode::UNAUTHORIZED.as_u16(),
        ))),
    }
}

async fn handle_predict_edits(mut req: Request, cx: RouteContext<()>) -> Result<Response> {
    let Some(authorization) = req.headers().get("authorization")? else {
        return Response::error(
            StatusCode::UNAUTHORIZED.as_str(),
            StatusCode::UNAUTHORIZED.as_u16(),
        );
    };

    let parts = authorization.split_whitespace().collect::<Vec<_>>();
    if parts.len() != 2 || parts[0].to_lowercase() != "bearer" {
        return Response::error(
            "Invalid authorization header",
            StatusCode::UNAUTHORIZED.as_u16(),
        );
    }

    let token = parts[1];

    let llm_token_secret = LlmTokenSecret(cx.secret("LLM_API_SECRET")?.to_string());

    let claims = match LlmTokenClaims::validate(token, &llm_token_secret) {
        Ok(claims) => claims,
        Err(err) => match err {
            ValidateLlmTokenError::Expired => {
                return Ok(Response::builder()
                    .with_status(StatusCode::UNAUTHORIZED.as_u16())
                    .with_header("x-zed-expired-token", "true")?
                    .fixed(StatusCode::UNAUTHORIZED.as_str().as_bytes().to_vec()))
            }
            ValidateLlmTokenError::JwtParseError(_)
            | ValidateLlmTokenError::JwtValidationError(_)
<|editable_region_end|>
            | ValidateLlmTokenError::Other(_) => {
```
</output>
<outline>
```crates/llm_worker/src/llm_worker.rs
mod token
pub async fn main
struct IndexResponse
fn handle_index
struct PredictEditsBody
 pub outline
 pub input_events
 pub input_excerpt
struct PredictEditsResponse
 pub output_excerpt
fn v
```

</outline>
<rejected>
```crates/llm_worker/src/llm_worker.rs
use telemetry_sink::{SnowflakeTelemetryEvent, SnowflakeTelemetrySink};
<|editable_region_start|>
use worker::*;

use crate::token::{LlmTokenClaims, LlmTokenSecret, ValidateLlmTokenError};

#[event(fetch)]
pub async fn main(req: Request, env: Env, _cx: worker::Context) -> Result<Response> {
    Router::new()
        .get("/", handle_index)
        .post_async("/predict_edits", handle_predict_edits)
        .run(req, env)
        .await
}

#[derive(Debug, Serialize, Deserialize)]
struct IndexResponse {}

fn handle_index(_req: Request, _cx: RouteContext<()>) -> Result<Response> {
    Response::from_json(&IndexResponse {})
}

#[derive(Debug, Deserialize)]
struct PredictEditsBody {
    pub outline: Option<String>,
    pub input_events: String,
    pub input_excerpt: String,
}

#[derive(Debug, Serialize)]
struct PredictEditsResponse {
    pub output_excerpt: String,
}

fn validate_request(req: &Request) -> Result<(), Response> {
    let Some(authorization) = req.headers().get("authorization")? else {
        return Err(Response::error(
            StatusCode::UNAUTHORIZED.as_str(),
            StatusCode::UNAUTHORIZED.as_u16(),
        ));
    };

    let parts = authorization.split_whitespace().collect::<Vec<_>>();
    if parts.len() != 2 || parts[0].to_lowercase() != "bearer" {
        return Err(Response::error(
            "Invalid authorization header",
            StatusCode::UNAUTHORIZED.as_u16(),
        ));
    }

    let token = parts[1];

    let llm_token_secret = LlmTokenSecret(cx.secret("LLM_API_SECRET")?.to_string());

    let claims = match LlmTokenClaims::validate(token, &llm_token_secret) {
        Ok(claims) => claims,
        Err(err) => match err {
            ValidateLlmTokenError::Expired => {
                return Ok(Response::builder()
                    .with_status(StatusCode::UNAUTHORIZED.as_u16())
                    .with_header("x-zed-expired-token", "true")?
                    .fixed(StatusCode::UNAUTHORIZED.as_str().as_bytes().to_vec()))
            }
            ValidateLlmTokenError::JwtParseError(_)
            | ValidateLlmTokenError::JwtValidationError(_)
<|editable_region_end|>
            | ValidateLlmTokenError::Other(_) => {
```
</rejected>

<labels>
non-local-edit,infer-refactor
</labels>
