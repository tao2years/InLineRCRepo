# 智能代码编辑功能数据处理管道设计方案

## 1. 数据转换策略

### 1.1 整体转换流程

```
原始Git Diff数据 → 差异分析 → 光标位置推断 → 可编辑区域确定 → 编辑历史构造 → 标签分类 → Zeta格式输出
```

### 1.2 核心转换逻辑

#### 输入数据结构映射
```python
class GitDiffRecord:
    def __init__(self, raw_data):
        self.file_path = raw_data['file_path']
        self.code_type = raw_data['code_type']
        self.old_file = raw_data['old_file']
        self.new_file = raw_data['new_file']
        self.review_line = raw_data['review_line']
        self.review_message = raw_data['review_message']
        self.old_hunk = raw_data['old_hunk']
        self.new_hunk = raw_data['new_hunk']
        self.code_with_line = raw_data['code_with_line']
```

#### 输出Zeta格式结构
```python
class ZetaTrainingRecord:
    def __init__(self):
        self.events = ""           # 编辑历史
        self.input = ""            # 带光标的输入代码
        self.output = ""           # 期望的输出代码
        self.labels = ""           # 两级标签
        self.assertions = ""       # 评估标准（仅评估数据）
```

## 2. 光标位置推断算法

### 2.1 基于review_line的光标定位

```python
def infer_cursor_position(git_record):
    """
    基于review_line和代码差异推断光标位置
    """
    # 1. 解析code_with_line获取行号映射
    line_mapping = parse_code_with_line(git_record.code_with_line)
    
    # 2. 定位review_line在old_file中的位置
    target_line_num = git_record.review_line
    target_line_content = line_mapping.get(target_line_num, "")
    
    # 3. 分析差异类型确定光标位置
    diff_type = analyze_diff_type(git_record.old_file, git_record.new_file)
    
    if diff_type == "line_deletion":
        # 删除场景：光标在被删除行的末尾
        cursor_pos = find_line_end_position(target_line_content)
    elif diff_type == "line_modification":
        # 修改场景：光标在修改点
        cursor_pos = find_modification_point(target_line_content, git_record.new_hunk)
    elif diff_type == "line_addition":
        # 添加场景：光标在插入点之前
        cursor_pos = find_insertion_point(target_line_content)
    
    return cursor_pos

def parse_code_with_line(code_with_line):
    """解析带行号的代码"""
    line_mapping = {}
    for line in code_with_line.split('\n'):
        if line.startswith('line '):
            parts = line.split(':', 1)
            if len(parts) == 2:
                line_num = int(parts[0].replace('line ', ''))
                line_content = parts[1]
                line_mapping[line_num] = line_content
    return line_mapping
```

### 2.2 可编辑区域确定策略

```python
def determine_editable_region(git_record, cursor_line):
    """
    确定可编辑区域的起始和结束位置
    """
    # 1. 基于代码结构分析确定上下文范围
    code_structure = analyze_code_structure(git_record.old_file, git_record.code_type)
    
    # 2. 根据修改类型调整区域大小
    diff_analysis = analyze_diff_scope(git_record.old_hunk, git_record.new_hunk)
    
    # 3. 确定区域边界
    if diff_analysis.scope == "method_level":
        # 方法级修改：包含整个方法
        start_line, end_line = find_method_boundaries(code_structure, cursor_line)
    elif diff_analysis.scope == "statement_level":
        # 语句级修改：包含相关语句块
        start_line, end_line = find_statement_boundaries(code_structure, cursor_line)
    else:
        # 表达式级修改：最小化区域
        start_line, end_line = find_minimal_boundaries(code_structure, cursor_line)
    
    return start_line, end_line
```

## 3. 编辑历史构造

### 3.1 Events字段生成策略

```python
def construct_edit_events(git_record):
    """
    基于git diff信息构造编辑历史
    """
    # 1. 分析old_hunk和new_hunk的差异
    diff_operations = parse_hunk_diff(git_record.old_hunk, git_record.new_hunk)
    
    # 2. 构造编辑事件描述
    events = []
    for operation in diff_operations:
        if operation.type == "deletion":
            event = f'User edited "{git_record.file_path}":\n\n```diff\n@@ -{operation.old_line_start},{operation.old_line_count} +{operation.new_line_start},{operation.new_line_count} @@\n'
            for line in operation.deleted_lines:
                event += f'-{line}\n'
            event += '```'
            
        elif operation.type == "addition":
            event = f'User edited "{git_record.file_path}":\n\n```diff\n@@ -{operation.old_line_start},{operation.old_line_count} +{operation.new_line_start},{operation.new_line_count} @@\n'
            for line in operation.added_lines:
                event += f'+{line}\n'
            event += '```'
            
        elif operation.type == "modification":
            event = f'User edited "{git_record.file_path}":\n\n```diff\n@@ -{operation.old_line_start},{operation.old_line_count} +{operation.new_line_start},{operation.new_line_count} @@\n'
            for old_line, new_line in zip(operation.old_lines, operation.new_lines):
                event += f'-{old_line}\n+{new_line}\n'
            event += '```'
        
        events.append(event)
    
    return '\n\n'.join(events)

def parse_hunk_diff(old_hunk, new_hunk):
    """
    解析hunk差异，提取具体的操作
    """
    # 使用difflib分析两个hunk的差异
    import difflib
    
    old_lines = old_hunk.split('\n') if old_hunk else []
    new_lines = new_hunk.split('\n') if new_hunk else []
    
    operations = []
    diff = list(difflib.unified_diff(old_lines, new_lines, lineterm=''))
    
    # 解析unified diff格式，提取操作类型
    current_operation = None
    for line in diff:
        if line.startswith('@@'):
            # 解析行号信息
            continue
        elif line.startswith('-'):
            if current_operation is None or current_operation.type != "deletion":
                current_operation = DiffOperation("deletion")
                operations.append(current_operation)
            current_operation.deleted_lines.append(line[1:])
        elif line.startswith('+'):
            if current_operation is None or current_operation.type != "addition":
                current_operation = DiffOperation("addition")
                operations.append(current_operation)
            current_operation.added_lines.append(line[1:])
    
    return operations
```

## 4. 标签自动分类系统

### 4.1 编辑位置分类算法

```python
def classify_edit_location(git_record, cursor_pos, editable_region):
    """
    分类编辑位置：no-op/local-edit/non-local-edit
    """
    # 1. 检查是否为no-op
    if git_record.old_file.strip() == git_record.new_file.strip():
        return "no-op"
    
    # 2. 分析修改位置与光标的距离
    modifications = find_all_modifications(git_record.old_file, git_record.new_file)
    
    cursor_line = get_line_number_from_position(git_record.old_file, cursor_pos)
    
    # 3. 判断修改是否在光标附近
    local_modifications = []
    non_local_modifications = []
    
    for mod in modifications:
        distance = abs(mod.line_number - cursor_line)
        if distance <= 3:  # 3行以内认为是local
            local_modifications.append(mod)
        else:
            non_local_modifications.append(mod)
    
    # 4. 根据修改分布决定分类
    if len(non_local_modifications) > 0:
        return "non-local-edit"
    elif len(local_modifications) > 0:
        return "local-edit"
    else:
        return "no-op"
```

### 4.2 编辑意图分类算法

```python
def classify_edit_intent(git_record):
    """
    分类编辑意图：add-imports/complete-implementation/complete-pattern/infer-intent/infer-refactor/unknown
    """
    # 1. 分析代码变化模式
    change_patterns = analyze_change_patterns(git_record.old_file, git_record.new_file)
    
    # 2. 基于模式匹配分类
    if has_import_additions(change_patterns):
        return "add-imports"
    
    elif has_method_implementation(change_patterns):
        return "complete-implementation"
    
    elif has_repetitive_pattern(change_patterns):
        return "complete-pattern"
    
    elif has_variable_renaming(change_patterns):
        return "infer-intent"
    
    elif has_code_restructuring(change_patterns):
        return "infer-refactor"
    
    else:
        return "unknown"

def analyze_change_patterns(old_code, new_code):
    """
    分析代码变化模式
    """
    patterns = {
        'import_additions': [],
        'method_implementations': [],
        'repetitive_changes': [],
        'variable_renamings': [],
        'code_restructuring': []
    }
    
    # 使用AST分析代码结构变化
    try:
        old_ast = parse_code_to_ast(old_code)
        new_ast = parse_code_to_ast(new_code)
        
        # 比较AST差异
        ast_diff = compare_ast(old_ast, new_ast)
        
        # 根据AST差异识别模式
        for diff in ast_diff:
            if diff.type == "import_node_added":
                patterns['import_additions'].append(diff)
            elif diff.type == "method_body_added":
                patterns['method_implementations'].append(diff)
            # ... 其他模式识别
                
    except Exception as e:
        # AST解析失败时使用文本分析
        patterns = analyze_text_patterns(old_code, new_code)
    
    return patterns

## 5. 评估数据生成

### 5.1 Assertions生成策略

```python
def generate_assertions(git_record):
    """
    基于review_message生成高质量的assertions
    """
    review_message = git_record.review_message
    code_change = analyze_code_change(git_record.old_file, git_record.new_file)

    # 1. 解析review_message提取关键信息
    review_analysis = parse_review_message(review_message)

    # 2. 基于代码变化和review信息生成assertions
    assertions = []

    if review_analysis.type == "functionality_issue":
        # 功能性问题：检查逻辑修复
        assertion = generate_functionality_assertion(code_change, review_analysis)
        assertions.append(assertion)

    elif review_analysis.type == "code_style":
        # 代码风格问题：检查格式和命名
        assertion = generate_style_assertion(code_change, review_analysis)
        assertions.append(assertion)

    elif review_analysis.type == "performance":
        # 性能问题：检查优化实现
        assertion = generate_performance_assertion(code_change, review_analysis)
        assertions.append(assertion)

    # 3. 添加通用检查assertions
    assertions.extend(generate_general_assertions(code_change))

    return '\n'.join(assertions)

def parse_review_message(message):
    """
    解析review消息，提取关键信息
    """
    # 示例：【功能性问题】为空是否也需要更新？不需要建议使用StringUtils.isBlank

    patterns = {
        'functionality': r'【功能性问题】(.+)',
        'style': r'【代码风格】(.+)',
        'performance': r'【性能问题】(.+)',
        'security': r'【安全问题】(.+)'
    }

    for issue_type, pattern in patterns.items():
        match = re.search(pattern, message)
        if match:
            return ReviewAnalysis(
                type=issue_type,
                description=match.group(1),
                suggestions=extract_suggestions(match.group(1))
            )

    return ReviewAnalysis(type="general", description=message, suggestions=[])

def generate_functionality_assertion(code_change, review_analysis):
    """
    生成功能性检查的assertion
    """
    # 基于具体的代码变化生成检查标准
    if "null check" in review_analysis.description.lower():
        return "Ensure that the test output properly handles null values and includes appropriate null checks"

    elif "stringutils" in review_analysis.description.lower():
        return "Ensure that the test output uses StringUtils.isBlank() instead of simple null checks for string validation"

    elif "exception handling" in review_analysis.description.lower():
        return "Ensure that the test output includes proper exception handling mechanisms"

    else:
        # 通用功能性检查
        return f"Ensure that the test output addresses the functionality concern: {review_analysis.description}"

## 6. 质量控制机制

### 6.1 格式验证

```python
def validate_zeta_format(zeta_record):
    """
    验证转换后的数据是否符合Zeta格式要求
    """
    errors = []

    # 1. 检查必需字段
    required_fields = ['events', 'input', 'output']
    for field in required_fields:
        if not hasattr(zeta_record, field) or not getattr(zeta_record, field):
            errors.append(f"Missing required field: {field}")

    # 2. 检查特殊标记
    input_content = zeta_record.input

    # 检查光标标记
    cursor_count = input_content.count('<|user_cursor_is_here|>')
    if cursor_count != 1:
        errors.append(f"Input must contain exactly one cursor marker, found {cursor_count}")

    # 检查可编辑区域标记
    start_count = input_content.count('<|editable_region_start|>')
    end_count = input_content.count('<|editable_region_end|>')
    if start_count != 1 or end_count != 1:
        errors.append(f"Input must contain exactly one editable region, found {start_count} start and {end_count} end markers")

    # 3. 检查输入输出一致性
    input_pre_editable = extract_pre_editable_content(input_content)
    output_pre_editable = extract_pre_editable_content(zeta_record.output)

    if input_pre_editable != output_pre_editable:
        errors.append("Content before editable region must be identical in input and output")

    # 4. 检查标签格式
    if hasattr(zeta_record, 'labels') and zeta_record.labels:
        if not validate_label_format(zeta_record.labels):
            errors.append("Invalid label format")

    return errors

def validate_label_format(labels):
    """
    验证标签格式是否正确
    """
    valid_location_labels = ['no-op', 'local-edit', 'non-local-edit']
    valid_intent_labels = ['add-imports', 'complete-implementation', 'complete-pattern',
                          'infer-intent', 'infer-refactor', 'unknown']

    label_parts = labels.split(',')
    if len(label_parts) != 2:
        return False

    location_label, intent_label = [label.strip() for label in label_parts]

    return (location_label in valid_location_labels and
            intent_label in valid_intent_labels)

### 6.2 质量评估

```python
def assess_data_quality(zeta_record):
    """
    评估转换后数据的质量
    """
    quality_score = 0
    max_score = 100

    # 1. 代码完整性检查 (30分)
    if is_code_syntactically_valid(zeta_record.input) and is_code_syntactically_valid(zeta_record.output):
        quality_score += 30

    # 2. 编辑合理性检查 (25分)
    edit_reasonableness = evaluate_edit_reasonableness(zeta_record.input, zeta_record.output)
    quality_score += int(edit_reasonableness * 25)

    # 3. 上下文相关性检查 (25分)
    context_relevance = evaluate_context_relevance(zeta_record.events, zeta_record.input)
    quality_score += int(context_relevance * 25)

    # 4. 标签准确性检查 (20分)
    label_accuracy = evaluate_label_accuracy(zeta_record)
    quality_score += int(label_accuracy * 20)

    return quality_score / max_score

## 7. 数据集划分策略

### 7.1 划分原则

```python
def split_dataset(processed_records):
    """
    将处理后的数据划分为训练集、评估集和DPO数据集
    """
    # 1. 按质量分层
    high_quality = [r for r in processed_records if assess_data_quality(r) >= 0.8]
    medium_quality = [r for r in processed_records if 0.6 <= assess_data_quality(r) < 0.8]
    low_quality = [r for r in processed_records if assess_data_quality(r) < 0.6]

    # 2. 按代码类型分层
    stratified_by_language = stratify_by_language(high_quality + medium_quality)

    # 3. 按编辑类型分层
    stratified_by_edit_type = stratify_by_edit_type(stratified_by_language)

    # 4. 执行划分
    train_data = []
    eval_data = []
    dpo_data = []

    for language, records in stratified_by_edit_type.items():
        # 确保每种语言和编辑类型在各个数据集中都有代表
        lang_train, lang_eval, lang_dpo = split_by_ratio(records, 0.7, 0.15, 0.15)

        train_data.extend(lang_train)
        eval_data.extend(lang_eval)
        dpo_data.extend(lang_dpo)

    return train_data, eval_data, dpo_data

def generate_dpo_pairs(base_records):
    """
    为DPO训练生成chosen/rejected对
    """
    dpo_pairs = []

    for record in base_records:
        # 1. 生成正确的chosen样本（基于原始数据）
        chosen = {
            'events': record.events,
            'input': record.input,
            'output': record.output,
            'labels': record.labels
        }

        # 2. 生成错误的rejected样本
        rejected_outputs = generate_rejected_outputs(record)

        for rejected_output in rejected_outputs:
            rejected = {
                'events': record.events,
                'input': record.input,
                'output': rejected_output,
                'labels': record.labels
            }

            dpo_pairs.append({
                'events': record.events,
                'input': record.input,
                'output': chosen['output'],
                'rejected': rejected['output'],
                'labels': record.labels
            })

    return dpo_pairs

def generate_rejected_outputs(record):
    """
    生成rejected样本的策略
    """
    rejected_outputs = []

    # 策略1：引入语法错误
    syntax_error_output = introduce_syntax_errors(record.output)
    rejected_outputs.append(syntax_error_output)

    # 策略2：不完整的编辑
    incomplete_output = generate_incomplete_edit(record.input, record.output)
    rejected_outputs.append(incomplete_output)

    # 策略3：过度编辑
    over_edit_output = generate_over_edit(record.input, record.output)
    rejected_outputs.append(over_edit_output)

    # 策略4：错误的编辑位置
    wrong_location_output = generate_wrong_location_edit(record.input, record.output)
    rejected_outputs.append(wrong_location_output)

    return rejected_outputs

## 8. 完整数据处理管道

### 8.1 主处理流程

```python
class DataProcessingPipeline:
    def __init__(self, config):
        self.config = config
        self.quality_threshold = config.get('quality_threshold', 0.6)

    def process(self, raw_git_diff_data):
        """
        完整的数据处理流程
        """
        processed_records = []
        failed_records = []

        for raw_record in raw_git_diff_data:
            try:
                # 1. 数据转换
                zeta_record = self.convert_to_zeta_format(raw_record)

                # 2. 质量验证
                validation_errors = validate_zeta_format(zeta_record)
                if validation_errors:
                    failed_records.append({
                        'record': raw_record,
                        'errors': validation_errors
                    })
                    continue

                # 3. 质量评估
                quality_score = assess_data_quality(zeta_record)
                if quality_score < self.quality_threshold:
                    failed_records.append({
                        'record': raw_record,
                        'reason': f'Low quality score: {quality_score}'
                    })
                    continue

                processed_records.append(zeta_record)

            except Exception as e:
                failed_records.append({
                    'record': raw_record,
                    'error': str(e)
                })

        # 4. 数据集划分
        train_data, eval_data, dpo_data = split_dataset(processed_records)

        # 5. 生成DPO对
        dpo_pairs = generate_dpo_pairs(dpo_data)

        return {
            'train': train_data,
            'eval': eval_data,
            'dpo': dpo_pairs,
            'failed': failed_records,
            'statistics': self.generate_statistics(train_data, eval_data, dpo_pairs)
        }

    def convert_to_zeta_format(self, git_record):
        """
        将git diff记录转换为Zeta格式
        """
        # 1. 推断光标位置和可编辑区域
        cursor_pos = infer_cursor_position(git_record)
        start_line, end_line = determine_editable_region(git_record, cursor_pos)

        # 2. 构造input字段
        input_code = construct_input_with_markers(
            git_record.old_file, cursor_pos, start_line, end_line
        )

        # 3. 构造output字段
        output_code = construct_output_with_markers(
            git_record.new_file, start_line, end_line
        )

        # 4. 构造events字段
        events = construct_edit_events(git_record)

        # 5. 分类标签
        location_label = classify_edit_location(git_record, cursor_pos, (start_line, end_line))
        intent_label = classify_edit_intent(git_record)
        labels = f"{location_label},{intent_label}"

        # 6. 生成assertions（如果是评估数据）
        assertions = ""
        if git_record.review_message:
            assertions = generate_assertions(git_record)

        return ZetaTrainingRecord(
            events=events,
            input=input_code,
            output=output_code,
            labels=labels,
            assertions=assertions
        )
```

## 9. 技术挑战与解决方案

### 9.1 主要技术挑战

1. **光标位置推断准确性**
   - 挑战：基于git diff信息准确推断用户光标位置
   - 解决方案：结合review_line、代码结构分析和启发式规则

2. **可编辑区域边界确定**
   - 挑战：确定合适的可编辑区域大小
   - 解决方案：基于AST分析和代码语义理解

3. **标签分类准确性**
   - 挑战：自动分类的准确性可能不够高
   - 解决方案：结合规则和机器学习方法，建立人工审核机制

4. **代码语法解析**
   - 挑战：多语言代码的语法解析复杂性
   - 解决方案：使用Tree-sitter等通用解析器，建立语言特定的处理逻辑

### 9.2 质量保证措施

1. **多层验证机制**
   - 格式验证、语法验证、语义验证
   - 人工抽样检查

2. **渐进式处理**
   - 先处理高质量、简单的样本
   - 逐步扩展到复杂场景

3. **反馈循环**
   - 收集处理结果反馈
   - 持续优化算法和规则

这个数据处理管道设计提供了从原始git diff数据到Zeta训练格式的完整转换方案，确保了数据质量和格式一致性，为智能代码编辑功能的训练提供了坚实的数据基础。
```
