# 智能代码编辑功能数据处理使用指南

## 概述

本数据处理管道基于Zeta项目的数据格式和处理逻辑，能够将git diff格式的原始数据转换为适用于智能代码编辑模型训练的标准格式。

## 快速开始

### 1. 环境准备

```bash
# 安装依赖
pip install pyyaml

# 确保Python版本 >= 3.7
python --version
```

### 2. 准备数据

将您的git diff数据整理为JSON或JSONL格式，每条记录包含以下字段：

```json
{
    "mrcr_url": "项目URL",
    "file_path": "文件路径",
    "code_type": "编程语言",
    "old_file": "修改前的完整文件内容",
    "new_file": "修改后的完整文件内容",
    "old_hunk": "修改前的代码片段",
    "new_hunk": "修改后的代码片段",
    "old_commit_id": "旧提交ID",
    "new_commit_id": "新提交ID",
    "review_line": 37,
    "review_message": "代码审查意见",
    "severity": "问题严重程度",
    "category": "问题类别",
    "author": "作者",
    "start_line": 37,
    "end_line": 37,
    "code_with_line": "带行号的代码上下文"
}
```

### 3. 运行处理

```bash
# 基本用法
python run_data_processing.py -i input_data.jsonl -o output_dir

# 使用自定义配置
python run_data_processing.py -i input_data.jsonl -o output_dir -c custom_config.yaml

# 试运行模式（不保存文件）
python run_data_processing.py -i input_data.jsonl -o output_dir --dry-run
```

### 4. 输出文件

处理完成后，输出目录将包含：

- `train.jsonl`: SFT训练数据
- `eval.jsonl`: 评估数据（包含assertions）
- `dpo.jsonl`: DPO训练数据
- `processing_stats.json`: 统计信息
- `processing_errors.json`: 失败记录
- `processing_report.md`: 处理报告

## 配置说明

### 主要配置项

#### 质量控制
```yaml
quality_control:
  quality_threshold: 0.6  # 质量阈值
  enable_syntax_validation: true
  manual_review_sample_rate: 0.1
```

#### 光标位置推断
```yaml
cursor_inference:
  inference_strategy: "heuristic"  # 推断策略
  max_search_range: 20  # 最大搜索范围
```

#### 可编辑区域确定
```yaml
editable_region:
  sizing_strategy: "adaptive"  # 区域大小策略
  region_sizes:
    minimal: 3
    statement: 5
    method: 15
```

#### 标签分类
```yaml
label_classification:
  location_thresholds:
    local_edit_max_distance: 3
  intent_rules:
    implementation_min_lines: 5
```

#### 数据集划分
```yaml
dataset_split:
  ratios:
    train: 0.70
    eval: 0.15
    dpo: 0.15
```

## 输出格式说明

### 训练数据格式 (train.jsonl)

```json
{
    "events": "User edited \"file.java\":\n\n```diff\n@@ -1,3 +1,4 @@\n-old line\n+new line\n```",
    "input": "code with <|editable_region_start|> and <|user_cursor_is_here|> markers <|editable_region_end|>",
    "output": "modified code with <|editable_region_start|> changes <|editable_region_end|>",
    "labels": "local-edit,complete-implementation"
}
```

### 评估数据格式 (eval.jsonl)

```json
{
    "events": "编辑历史",
    "input": "输入代码",
    "output": "期望输出",
    "labels": "标签",
    "assertions": "Ensure that the test output properly handles null values"
}
```

### DPO数据格式 (dpo.jsonl)

```json
{
    "events": "编辑历史",
    "input": "输入代码",
    "output": "正确输出",
    "rejected": "错误输出",
    "labels": "标签"
}
```

## 标签系统

### 编辑位置标签
- `no-op`: 无修改
- `local-edit`: 光标附近的编辑
- `non-local-edit`: 远离光标的编辑

### 编辑意图标签
- `add-imports`: 添加导入语句
- `complete-implementation`: 完成函数实现
- `complete-pattern`: 完成模式匹配
- `infer-intent`: 推断用户意图
- `infer-refactor`: 推断重构意图
- `unknown`: 未知类型

## 质量控制

### 自动验证
1. **格式验证**: 检查必需字段和特殊标记
2. **语法验证**: 验证代码语法正确性
3. **一致性验证**: 检查输入输出的一致性
4. **标签验证**: 验证标签格式和合理性

### 质量评估
- **代码完整性**: 语法有效性检查
- **编辑合理性**: 编辑幅度和逻辑性评估
- **上下文相关性**: 编辑历史与代码的相关性
- **标签准确性**: 标签与实际编辑的匹配度

## 常见问题

### Q1: 处理失败率过高怎么办？
A: 检查原始数据质量，调整配置中的质量阈值，查看失败记录分析具体原因。

### Q2: 光标位置推断不准确？
A: 调整`cursor_inference`配置，特别是`max_search_range`参数，或考虑使用更精确的推断策略。

### Q3: 标签分类不合理？
A: 检查`label_classification`配置，调整阈值参数，或添加自定义分类规则。

### Q4: 生成的assertions质量不高？
A: 改进review_message的质量，或自定义assertions生成模板。

## 扩展开发

### 自定义处理器

```python
class CustomProcessor:
    def process(self, git_record):
        # 自定义处理逻辑
        pass

# 在配置中启用
extensions:
  custom_processors: ["CustomProcessor"]
```

### 添加新语言支持

```yaml
cursor_inference:
  language_configs:
    rust:
      method_keywords: ["fn", "impl", "struct"]
      block_start: "{"
      block_end: "}"
      indent_size: 4
```

### 自定义标签规则

```python
def custom_intent_classifier(git_record):
    # 自定义意图分类逻辑
    if "test" in git_record.file_path:
        return "add-tests"
    return "unknown"
```

## 性能优化

### 并行处理
```yaml
performance:
  enable_multiprocessing: true
  max_workers: 4
  batch_size: 100
```

### 内存管理
```yaml
performance:
  max_memory_usage: "2GB"
  enable_garbage_collection: true
```

## 监控和调试

### 日志配置
```yaml
logging:
  level: "DEBUG"  # 详细日志
  log_file: "debug.log"
  enable_detailed_stats: true
```

### 错误处理
```yaml
error_handling:
  max_error_rate: 0.1
  on_failure: "skip"  # 跳过失败的记录
  max_retries: 3
```

## 最佳实践

1. **数据预处理**: 确保原始数据质量，清理无效记录
2. **配置调优**: 根据数据特点调整配置参数
3. **质量监控**: 定期检查处理结果和失败记录
4. **增量处理**: 对于大数据集，考虑分批处理
5. **版本管理**: 保存配置文件和处理脚本的版本

## 技术支持

如遇到问题，请检查：
1. 日志文件中的错误信息
2. 失败记录中的具体错误
3. 配置文件的参数设置
4. 原始数据的格式和质量

更多技术细节请参考：
- `数据处理管道设计方案.md`: 详细的技术设计
- `data_processor.py`: 核心处理逻辑
- `process_config.yaml`: 完整的配置选项
